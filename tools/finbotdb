#!/usr/bin/env python3.7
from collections import defaultdict
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine
from finbot.providers import dummy_uk
from finbot.core.utils import pretty_dump
from finbot.core import fx
from finbot.model import (
    Base,
    Provider,
    UserAccount,
    UserAccountSettings,
    LinkedAccount,
    UserAccountHistoryEntry,
    UserAccountValuationHistoryEntry,
    LinkedAccountValuationHistoryEntry,
    SubAccountValuationHistoryEntry,
    SubAccountItemValuationHistoryEntry,
    ValuationChangeEntry,
    SubAccountItemType
)
from finbot.core import crypto
import logging.config
import logging
import pandas as pd
import datetime
import argparse
import json
import pytz
import csv


logging.config.dictConfig({
    'version': 1,
    'formatters': {'default': {
        'format': '%(asctime)s [%(levelname)s] %(message)s (%(filename)s:%(lineno)d)',
    }},
    'handlers': {'wsgi': {
        'class': 'logging.StreamHandler',
        'stream': 'ext://sys.stdout',
        'formatter': 'default'
    }},
    'root': {
        'level': 'DEBUG',
        'handlers': ['wsgi']
    }
})


BIG_PANDA = pd.option_context('display.max_rows', None, 'display.max_columns', None, "display.width", 1000)


def build_tool(settings, engine, session):
    Base.metadata.create_all(engine)


def destroy_tool(settings, engine, session):
    Base.metadata.drop_all(engine)


def generate_dummy_historical_valuation(user_account: UserAccount,
                                        valuation_ccy: str,
                                        start_amount: float,
                                        start_time: datetime.datetime,
                                        end_time: datetime.datetime, 
                                        interval: datetime.timedelta,
                                        period_contribution: float,
                                        yearly_rate: float):
    assert end_time > start_time
    valuations = []
    current_time = start_time
    current_amount = start_amount
    seconds_in_year = 3600 * 24 * 364
    interval_rate = yearly_rate * (interval.total_seconds() / seconds_in_year)
    while current_time <= end_time:
        valuations.append((current_time, current_amount))
        current_amount = (current_amount * (1 + interval_rate)) + period_contribution
        current_time += interval

    linked_accounts = user_account.linked_accounts
    dummy_account = dummy_uk.DUMMY_ACCOUNT

    return [
        UserAccountHistoryEntry(
            user_account=user_account,
            valuation_ccy=valuation_ccy,
            effective_at=valuation_time,
            available=True,
            user_account_valuation_history_entry=UserAccountValuationHistoryEntry(
                valuation=valuation * len(linked_accounts)),
            linked_accounts_valuation_history_entries=[
                LinkedAccountValuationHistoryEntry(
                    linked_account=linked_account,
                    valuation=valuation
                )
                for linked_account in linked_accounts
            ],
            sub_accounts_valuation_history_entries=[
                SubAccountValuationHistoryEntry(
                    linked_account=linked_account,
                    sub_account_id=dummy_account["id"],
                    sub_account_ccy=dummy_account["iso_currency"],
                    sub_account_description=dummy_account["name"],
                    valuation=valuation,
                    valuation_sub_account_ccy=valuation
                )
                for linked_account in linked_accounts
            ],
            sub_accounts_items_valuation_history_entries=[
                SubAccountItemValuationHistoryEntry(
                    linked_account=linked_account,
                    sub_account_id=dummy_account["id"],
                    item_type=SubAccountItemType.Asset,
                    name="cash",
                    item_subtype="cash",
                    valuation=valuation,
                    valuation_sub_account_ccy=valuation
                )
                for linked_account in linked_accounts
            ]
        )
        for valuation_time, valuation in valuations
    ]


def general_real_historical_valuation(history_file_path, 
                                      user_account: UserAccount):
    entries = []
    valuation_ccy = user_account.settings.valuation_ccy
    with open(history_file_path, "r") as f:
        reader = csv.DictReader(f, delimiter=";")
        for row in reader:
            valuation_date = datetime.datetime(*list(reversed(list(int(v) for v in row["date"].split("-")))), tzinfo=pytz.utc)
            entries.append([
                valuation_date,
                row["provider"],
                row["account_id"],
                float(row["amount"]),
                row["ccy"],
                float(row["amount"]) * fx.get_xccy_rate_cached(row["ccy"], valuation_ccy, valuation_date),
                valuation_ccy
            ])

    df = pd.DataFrame.from_records(entries, columns=[
        "date", 
        "provider", 
        "account_id", 
        "amount_account_ccy", 
        "account_ccy",
        "amount_snapshot_ccy",
        "snapshot_ccy"
    ]).sort_values(by=["date"])

    val_by_date = df.groupby(["date"])["amount_snapshot_ccy"].sum()
    val_by_date_provider = df.groupby(["date", "provider"])["amount_snapshot_ccy"].sum()
    val_by_date_sub_account = df.groupby(["date", "provider", "account_id", "account_ccy"]).agg({
        "amount_snapshot_ccy": "sum",
        "amount_account_ccy": "sum"
    }).to_dict()
    val_by_date_sub_account = {
        path: (acc_val, val_by_date_sub_account["amount_snapshot_ccy"][path])
        for path, acc_val in val_by_date_sub_account["amount_account_ccy"].items()
    }

    linked_account_by_provider = {
        linked_account.provider_id: linked_account
        for linked_account in user_account.linked_accounts 
    }

    return [
        UserAccountHistoryEntry(
            user_account=user_account,
            valuation_ccy=valuation_ccy,
            effective_at=val_date,
            available=True,
            user_account_valuation_history_entry=UserAccountValuationHistoryEntry(
                valuation=amount),
            linked_accounts_valuation_history_entries=[
                LinkedAccountValuationHistoryEntry(
                    linked_account=linked_account_by_provider[provider_id],
                    valuation=linked_amount
                )
                for (val_date0, provider_id), linked_amount 
                in val_by_date_provider.iteritems()
                if val_date0 == val_date
            ],
            sub_accounts_valuation_history_entries=[
                SubAccountValuationHistoryEntry(
                    linked_account=linked_account_by_provider[provider_id],
                    sub_account_id=sub_account_id,
                    sub_account_ccy=sub_account_ccy,
                    sub_account_description=sub_account_id,
                    valuation=snap_val,
                    valuation_sub_account_ccy=acc_val
                )
                for (val_date0, provider_id, sub_account_id, sub_account_ccy), (acc_val, snap_val)
                in val_by_date_sub_account.items()
                if val_date0 == val_date
            ]
        )
        for val_date, amount in val_by_date.iteritems()
    ]

def hydrate_tool(settings, engine, session):
    with open(settings.secret) as kf:
        secret = kf.read()
        with open(settings.accounts, "rb") as af:
            accounts = json.loads(crypto.fernet_decrypt(af.read(), secret))["accounts"]

    providers = {
        "vanguard_uk": Provider(
            id="vanguard_uk",
            description="Vanguard Investors (UK)",
            website_url="https://www.vanguardinvestor.co.uk/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "username": {
                        "type": "string",
                    },
                    "password": {
                        "type": "string",
                    }
                }
            }
        ),
        "aegon_targetplan_uk": Provider(
            id="aegon_targetplan_uk",
            description="Aegon Targetplan (UK)",
            website_url="https://lwp.aegon.co.uk/targetplanUI/login",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "email": {
                        "type": "idn-email",
                    },
                    "password": {
                        "type": "string",
                    }
                }
            }
        ),
        "barclays_uk": Provider(
            id="barclays_uk",
            description="Barclays (UK)",
            website_url="https://www.barclays.co.uk/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "last_name": {
                        "type": "string",
                    },
                    "card_number": {
                        "type": "string",
                        "pattern": r"\d{4}-\d{4}-\d{4}-\d{4}"
                    },
                    "passcode": {
                        "type": "string",
                        "pattern": r"\d{5}"
                    },
                    "memorable_word": {
                        "type": "string"
                    }
                }
            }
        ),
        "ca_fr": Provider(
            id="ca_fr",
            description="Credit Agricole (FR)",
            website_url="https://www.credit-agricole.fr/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "account_number": {
                        "type": "string",
                        "pattern": r"\d+"
                    },
                    "password": {
                        "type": "string",
                        "pattern": r"\d{6}"
                    }
                }
            }
        ),
        "lending_works_uk": Provider(
            id="lending_works_uk",
            description="Lending Works (UK)",
            website_url="https://www.lendingworks.co.uk/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "email": {
                        "type": "idn-email",
                    },
                    "password": {
                        "type": "string",
                    }
                }
            }
        ),
        "october_fr": Provider(
            id="october_fr",
            description="October (FR)",
            website_url="https://fr.october.eu/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "email": {
                        "type": "idn-email",
                    },
                    "password": {
                        "type": "string",
                    }
                }
            }
        ),
        "kraken_us": Provider(
            id="kraken_us",
            description="Kraken (US)",
            website_url="https://www.kraken.com/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "api_key": {
                        "type": "string",
                    },
                    "private_key": {
                        "type": "string",
                    }
                }
            }
        ),
        "bittrex_us": Provider(
            id="bittrex_us",
            description="Bittrex (US)",
            website_url="https://global.bittrex.com/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "api_key": {
                        "type": "string",
                    },
                    "private_key": {
                        "type": "string",
                    }
                }
            }
        ),
        "dummy_uk": Provider(
            id="dummy_uk",
            description="Dummy (fake) provider (UK)",
            website_url="https://dummy.co.uk/",
            credentials_schema={}
        )
    }
    session.add_all(providers.values())

    user_accounts = [
        UserAccount(
            email="test1@finbot.net",
            encrypted_password=crypto.fernet_encrypt(
                "test".encode(), secret).decode(),
            full_name="Test user (1)",
            settings=UserAccountSettings(
                valuation_ccy="USD"
            ),
            linked_accounts=[
                LinkedAccount(
                    provider=providers[account["provider_id"]],
                    account_name=providers[account["provider_id"]].description,
                    encrypted_credentials=crypto.fernet_encrypt(
                        json.dumps(account["credentials"]).encode(), secret).decode()
                )
                for account in accounts
                if account["provider_id"] in {"dummy_uk"}
            ]
        ),
        UserAccount(
            email="test2@finbot.net",
            encrypted_password=crypto.fernet_encrypt(
                "test".encode(), secret).decode(),
            full_name="Test user (2)",
            settings=UserAccountSettings(
                valuation_ccy="EUR"
            ),
            linked_accounts=[
                LinkedAccount(
                    provider=providers[account["provider_id"]],
                    account_name=providers[account["provider_id"]].description,
                    encrypted_credentials=crypto.fernet_encrypt(
                        json.dumps(account["credentials"]).encode(), secret).decode()
                )
                for account in accounts
                if account["provider_id"] not in {"dummy_uk"}
            ]
        )
    ]

    session.add_all(user_accounts)
    session.commit()

    logging.info("adding fake historical valuation")

    dummy_account = user_accounts[0]
    session.add_all(
        generate_dummy_historical_valuation(
            user_account=dummy_account,
            valuation_ccy=dummy_account.settings.valuation_ccy,
            start_amount=10.0,
            start_time=datetime.datetime(year=2018, month=1, day=1, tzinfo=pytz.utc),
            end_time=datetime.datetime.now(tz=pytz.utc),
            interval=datetime.timedelta(days=1),
            period_contribution=2,
            yearly_rate=0.05))
    session.commit()

    real_account = user_accounts[1]
    if settings.history:
        logging.info("adding real historical valuation")
        assert len(settings.history) == 1
        session.add_all(
            general_real_historical_valuation(settings.history[0], real_account))
        session.commit()


def setup_hydrate_subparser(parser):
    parser.add_argument("history", metavar="history", nargs='*')
    parser.add_argument("-k", "--secret", type=str, help="path to secret key", required=True)
    parser.add_argument("-A", "--accounts", type=str, help="path to accounts file", required=True)


def create_parser():
    parser = argparse.ArgumentParser(prog='finbotdb utility')
    subparsers = parser.add_subparsers(help='tools')
    for tool_name, tool in all_tools.items():
        subparser = subparsers.add_parser(tool_name, help=tool["description"])
        subparser.set_defaults(tool_name=tool_name)
        tool["parser_builder"](subparser)
    return parser


all_tools = {
    "build": {
        "description": "create all tables in database",
        "parser_builder": (lambda _: None),
        "handler": build_tool
    },
    "destroy": {
        "description": "remove all tables in database",
        "parser_builder": (lambda _: None),
        "handler": destroy_tool
    },
    "hydrate": {
        "description": "hydrate database with initial (test) data",
        "parser_builder": setup_hydrate_subparser,
        "handler": hydrate_tool
    }
}


def main():
    parser = create_parser()
    settings = parser.parse_args()
    if not hasattr(settings, "tool_name"):
        parser.print_usage()
        return
    db_engine = create_engine('postgresql+psycopg2://finbot:finbot@127.0.0.1/finbot')
    db_session = sessionmaker(bind=db_engine)()
    return all_tools[settings.tool_name]["handler"](settings, db_engine, db_session)


if __name__ == "__main__":
    main()
