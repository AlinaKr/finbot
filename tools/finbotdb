#!/usr/bin/env python3.7
from collections import defaultdict
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine
from finbot.providers import dummy_uk
from finbot.core.utils import pretty_dump
from finbot.core import fx
from finbot.model import (
    Base,
    Provider,
    UserAccount,
    UserAccountSettings,
    LinkedAccount,
    UserAccountHistoryEntry,
    UserAccountValuationHistoryEntry,
    LinkedAccountValuationHistoryEntry,
    SubAccountValuationHistoryEntry,
    SubAccountItemValuationHistoryEntry,
    ValuationChangeEntry,
    SubAccountItemType
)
from finbot.core import crypto
import logging.config
import logging
import random
import pandas as pd
import datetime
import argparse
import json
import pytz
import csv


logging.config.dictConfig({
    'version': 1,
    'formatters': {'default': {
        'format': '%(asctime)s [%(levelname)s] %(message)s (%(filename)s:%(lineno)d)',
    }},
    'handlers': {'wsgi': {
        'class': 'logging.StreamHandler',
        'stream': 'ext://sys.stdout',
        'formatter': 'default'
    }},
    'root': {
        'level': 'DEBUG',
        'handlers': ['wsgi']
    }
})


def build_tool(settings, engine, session):
    Base.metadata.create_all(engine)


def destroy_tool(settings, engine, session):
    Base.metadata.drop_all(engine)


# will be fixed when needed
"""
def general_real_historical_valuation(history_file_path, 
                                      user_account: UserAccount):
    entries = []
    valuation_ccy = user_account.settings.valuation_ccy
    with open(history_file_path, "r") as f:
        reader = csv.DictReader(f, delimiter=";")
        for row in reader:
            valuation_date = datetime.datetime(*list(reversed(list(int(v) for v in row["date"].split("-")))), tzinfo=pytz.utc)
            entries.append([
                valuation_date,
                row["provider"],
                row["account_id"],
                float(row["amount"]),
                row["ccy"],
                float(row["amount"]) * fx.get_xccy_rate_cached(row["ccy"], valuation_ccy, valuation_date),
                valuation_ccy
            ])

    df = pd.DataFrame.from_records(entries, columns=[
        "date", 
        "provider", 
        "account_id", 
        "amount_account_ccy", 
        "account_ccy",
        "amount_snapshot_ccy",
        "snapshot_ccy"
    ]).sort_values(by=["date"])

    val_by_date = df.groupby(["date"])["amount_snapshot_ccy"].sum()
    val_by_date_provider = df.groupby(["date", "provider"])["amount_snapshot_ccy"].sum()
    val_by_date_sub_account = df.groupby(["date", "provider", "account_id", "account_ccy"]).agg({
        "amount_snapshot_ccy": "sum",
        "amount_account_ccy": "sum"
    }).to_dict()
    val_by_date_sub_account = {
        path: (acc_val, val_by_date_sub_account["amount_snapshot_ccy"][path])
        for path, acc_val in val_by_date_sub_account["amount_account_ccy"].items()
    }

    linked_account_by_provider = {
        linked_account.provider_id: linked_account
        for linked_account in user_account.linked_accounts 
    }

    return [
        UserAccountHistoryEntry(
            user_account=user_account,
            valuation_ccy=valuation_ccy,
            effective_at=val_date,
            available=True,
            user_account_valuation_history_entry=UserAccountValuationHistoryEntry(
                valuation=amount),
            linked_accounts_valuation_history_entries=[
                LinkedAccountValuationHistoryEntry(
                    linked_account=linked_account_by_provider[provider_id],
                    valuation=linked_amount
                )
                for (val_date0, provider_id), linked_amount 
                in val_by_date_provider.iteritems()
                if val_date0 == val_date
            ],
            sub_accounts_valuation_history_entries=[
                SubAccountValuationHistoryEntry(
                    linked_account=linked_account_by_provider[provider_id],
                    sub_account_id=sub_account_id,
                    sub_account_ccy=sub_account_ccy,
                    sub_account_description=sub_account_id,
                    valuation=snap_val,
                    valuation_sub_account_ccy=acc_val
                )
                for (val_date0, provider_id, sub_account_id, sub_account_ccy), (acc_val, snap_val)
                in val_by_date_sub_account.items()
                if val_date0 == val_date
            ]
        )
        for val_date, amount in val_by_date.iteritems()
    ]
"""


def hydrate_tool(settings, engine, session):
    providers = [
        Provider(
            id="amex_us",
            description="American express (US)",
            website_url="https://www.americanexpress.com/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "user_id": {
                        "type": "string",
                    },
                    "password": {
                        "type": "string",
                    }
                }
            }
        ),
        Provider(
            id="vanguard_uk",
            description="Vanguard Investors (UK)",
            website_url="https://www.vanguardinvestor.co.uk/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "username": {
                        "type": "string",
                    },
                    "password": {
                        "type": "string",
                    }
                }
            }
        ),
        Provider(
            id="aegon_targetplan_uk",
            description="Aegon Targetplan (UK)",
            website_url="https://lwp.aegon.co.uk/targetplanUI/login",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "email": {
                        "type": "idn-email",
                    },
                    "password": {
                        "type": "string",
                    }
                }
            }
        ),
        Provider(
            id="barclays_uk",
            description="Barclays (UK)",
            website_url="https://www.barclays.co.uk/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "last_name": {
                        "type": "string",
                    },
                    "card_number": {
                        "type": "string",
                        "pattern": r"\d{4}-\d{4}-\d{4}-\d{4}"
                    },
                    "passcode": {
                        "type": "string",
                        "pattern": r"\d{5}"
                    },
                    "memorable_word": {
                        "type": "string"
                    }
                }
            }
        ),
        Provider(
            id="barclaycard",
            description="Barclaycard (UK)",
            website_url="https://www.barclaycard.co.uk/personal/customer",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "username": {
                        "type": "string"
                    },
                    "passcode": {
                        "type": "string",
                        "pattern": r"\d{6}"
                    },
                    "memorable_word": {
                        "type": "string"
                    }
                }
            }
        ),
        Provider(
            id="ca_fr",
            description="Credit Agricole (FR)",
            website_url="https://www.credit-agricole.fr/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "account_number": {
                        "type": "string",
                        "pattern": r"\d+"
                    },
                    "password": {
                        "type": "string",
                        "pattern": r"\d{6}"
                    }
                }
            }
        ),
        Provider(
            id="lending_works_uk",
            description="Lending Works (UK)",
            website_url="https://www.lendingworks.co.uk/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "email": {
                        "type": "idn-email"
                    },
                    "password": {
                        "type": "string"
                    }
                }
            }
        ),
        Provider(
            id="october_fr",
            description="October (FR)",
            website_url="https://fr.october.eu/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "email": {
                        "type": "idn-email"
                    },
                    "password": {
                        "type": "string"
                    }
                }
            }
        ),
        Provider(
            id="kraken_us",
            description="Kraken (US)",
            website_url="https://www.kraken.com/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "api_key": {
                        "type": "string"
                    },
                    "private_key": {
                        "type": "string"
                    }
                }
            }
        ),
        Provider(
            id="bittrex_us",
            description="Bittrex (US)",
            website_url="https://global.bittrex.com/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "api_key": {
                        "type": "string"
                    },
                    "private_key": {
                        "type": "string"
                    }
                }
            }
        ),
        Provider(
            id="google_sheets",
            description="Portfolio managed via Google sheets",
            website_url="https://www.google.com/sheets/about/",
            credentials_schema={
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "sheet_key": {
                        "type": "string"
                    },
                    "google_api_credentials": {
                        "type": "object"
                    }
                }
            }
        ),
        Provider(
            id="dummy_uk",
            description="Dummy (fake) provider (UK)",
            website_url="https://dummy.co.uk/",
            credentials_schema={}
        )
    ]

    session.add_all(providers)
    session.commit()

    logging.info("hydrated finbotdb with default data")


def parse_input_date(date_str):
    if date_str == "now":
        return datetime.datetime.now()
    return datetime.datetime.strptime(date_str, "%d-%b-%Y")


def handle_fake_data_source(user_account: UserAccount,
                            initial_amount,
                            rate,
                            contributions,
                            period_days,
                            start_date,
                            end_date):
    seconds_in_year = 3600 * 24 * 364
    start_date = parse_input_date(start_date)
    end_date = parse_input_date(end_date)
    assert end_date > start_date
    min_rate, max_rate = rate
    min_contribution, max_contribution = contributions
    period = datetime.timedelta(days=period_days)

    linked_accounts = user_account.linked_accounts

    valuations = [(start_date, [initial_amount] * len(linked_accounts))]
    while True:
        previous_time, previous_values = valuations[-1]
        current_time = previous_time + period
        if current_time > end_date:
            break

        current_values = []
        for valuation_idx in range(len(linked_accounts)):
            current_value =  previous_values[valuation_idx]
            period_contribution = random.uniform(min_contribution, max_contribution)
            yearly_rate = random.uniform(min_rate, max_rate)
            period_rate = yearly_rate * (period.total_seconds() / seconds_in_year)
            current_values.append((current_value * (1.0 + period_rate)) + period_contribution)
        valuations.append((current_time, current_values))

    currency = user_account.settings.valuation_ccy
    sub_account_id = "checkings"

    return [
        UserAccountHistoryEntry(
            user_account=user_account,
            valuation_ccy=currency,
            effective_at=valuation_date,
            available=True,
            user_account_valuation_history_entry=UserAccountValuationHistoryEntry(
                valuation=sum(values)),
            linked_accounts_valuation_history_entries=[
                LinkedAccountValuationHistoryEntry(
                    linked_account=linked_account,
                    valuation=value
                )
                for value, linked_account in zip(values, linked_accounts)
            ],
            sub_accounts_valuation_history_entries=[
                SubAccountValuationHistoryEntry(
                    linked_account=linked_account,
                    sub_account_id=sub_account_id,
                    sub_account_ccy=currency,
                    sub_account_description=sub_account_id,
                    valuation=value,
                    valuation_sub_account_ccy=value
                )
                for value, linked_account in zip(values, linked_accounts)
            ],
            sub_accounts_items_valuation_history_entries=[
                SubAccountItemValuationHistoryEntry(
                    linked_account=linked_account,
                    sub_account_id=sub_account_id,
                    item_type=SubAccountItemType.Asset,
                    name="cash",
                    item_subtype="currency",
                    valuation=value,
                    valuation_sub_account_ccy=value
                )
                for value, linked_account in zip(values, linked_accounts)
            ]
        )
        for valuation_date, values in valuations
    ]


def add_account_tool(settings, engine, session):
    with open(settings.secret) as kf:
        secret = kf.read()
        with open(settings.account, "rb") as af:
            account_data = json.loads(crypto.fernet_decrypt(af.read(), secret))

    # 1. find all available providers

    all_providers = {
        provider.id: provider
        for provider in  session.query(Provider).all()
    }

    # 2. create user account for account file
    user_account_data = account_data["user_account"]
    new_account = UserAccount(
        email=user_account_data["email"],
        encrypted_password=crypto.fernet_encrypt(
            user_account_data["password"].encode(), secret).decode(),
        full_name=user_account_data["full_name"],
        settings=UserAccountSettings(
            valuation_ccy=user_account_data["settings"]["valuation_ccy"]
        ),
        linked_accounts=[
            LinkedAccount(
                provider=all_providers[linked_account["provider_id"]],
                account_name=linked_account["description"],
                encrypted_credentials=crypto.fernet_encrypt(
                    json.dumps(linked_account["credentials"]).encode(), secret).decode()
            )
            for linked_account in account_data["linked_accounts"]
        ]
    )

    session.add(new_account)
    session.commit()

    data_source = account_data.get("data_source")
    if data_source:
        data_source_type = list(data_source.keys())[0]
        data_source_handlers = {
            "fake": handle_fake_data_source
        }
        handler = data_source_handlers[data_source_type]
        session.add_all(handler(new_account, **data_source[data_source_type]))
        session.commit()

    logging.info(f"user account '{new_account.id}' created")


def setup_add_account_subparser(parser):
    parser.add_argument("-k", "--secret", type=str, help="path to secret key", required=True)
    parser.add_argument("-A", "--account", type=str, help="path to account file", required=True)


def create_parser():
    parser = argparse.ArgumentParser(prog='finbotdb utility')
    subparsers = parser.add_subparsers(help='tools')
    for tool_name, tool in all_tools.items():
        subparser = subparsers.add_parser(tool_name, help=tool["description"])
        subparser.set_defaults(tool_name=tool_name)
        tool["parser_builder"](subparser)
    return parser


all_tools = {
    "build": {
        "description": "create all tables in database",
        "parser_builder": (lambda _: None),
        "handler": build_tool
    },
    "destroy": {
        "description": "remove all tables in database",
        "parser_builder": (lambda _: None),
        "handler": destroy_tool
    },
    "hydrate": {
        "description": "hydrate database with minimal data",
        "parser_builder": (lambda _: None),
        "handler": hydrate_tool
    },
    "add-account": {
        "description": "adds the current test account to the database",
        "parser_builder": setup_add_account_subparser,
        "handler": add_account_tool
    }
}


def main():
    parser = create_parser()
    settings = parser.parse_args()
    if not hasattr(settings, "tool_name"):
        parser.print_usage()
        return
    db_engine = create_engine('postgresql+psycopg2://finbot:finbot@127.0.0.1/finbot')
    db_session = sessionmaker(bind=db_engine)()
    return all_tools[settings.tool_name]["handler"](settings, db_engine, db_session)


if __name__ == "__main__":
    main()
